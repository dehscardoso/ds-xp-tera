{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc917c90",
   "metadata": {},
   "source": [
    "<img src = \"https://images2.imgbox.com/c1/79/4H1V1tSO_o.png\" width=\"1200\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45dbbb54",
   "metadata": {},
   "source": [
    "# Métricas de Classificação\n",
    "---\n",
    "\n",
    "Modelos de classificação, um tipo de aplicação de Machine Learning, são utilizados para resolver problemas em que se faz necessário particionar um espaço amostral de modo que os dados sejam agrupados por semelhança ou discrepância em relação a determinadas características. \n",
    "\n",
    "Basicamente, modelos de classificação indicam quantas observações satisfazem uma determinada condição e quantas não a satisfazem. Na área da saúde, por exemplo, esses modelos podem ser utilizados para classificar se um paciente está saudável ou doente a partir de um teste. A detecção de fraude em transações bancárias também é outra aplicação na qual esta análise é fundamental.  \n",
    "\n",
    "Avaliar objetivamente a solução obtida com o treinamento de um modelo de classificação é fundamental para nortear as decisões ao longo de seu desenvolvimento. As métricas de classificação são indicadores que podemos utilizar para fazer essa avaliação, por meio delas verificamos se um modelo resolve o problema proposto ou não. Além disso, também são utilizadas para comparar diferentes abordagens e decidir quais delas são mais promissoras. A seguir vamos exemplificar as principais métricas a partir da Matriz de Confusão. \n",
    "\n",
    "## Matriz de confusão\n",
    "---\n",
    "\n",
    "A Matriz de Confusão é, basicamente, uma tabela que resume os acertos e erros do modelo de classificação em relação ao resultado esperado. Essa matriz apresenta os verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos, conforme apresentado abaixo:\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/a0/ba/FqNODLoU_o.png\" width=\"800\">\n",
    "\n",
    "Por meio dela é possível analisar o desempenho do modelo em relação a cada uma das classes de forma independente. Para ilustrar essa ideia, considere que estamos analisando a performance de um teste que detecta se um paciente está ou não gripado, ou seja, positivo significa que a pessoa está doente e negativo indica que está saudável. Dada uma amostra de 10 pacientes dos quais sabemos que 5 estão saudáveis e 5 estão doentes, suponha que o modelo de classificação performou segundo a matriz de confusão apresentada abaixo:\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/8d/8b/hCLYiHXK_o.png\" width=\"800\">\n",
    "\n",
    "\n",
    "Observe que a diagonal principal da matriz contém os acertos: \n",
    "\n",
    "- 3 pessoas **doentes** foram classificadas como **doentes** (verdadeiro positivo);\n",
    "\n",
    "- 3 pessoas **saudáveis** foram classificadas como **saudáveis** (verdadeiro negativo).\n",
    "\n",
    "A diagonal secundária da matriz apresenta as classificações erradas do modelo:\n",
    "\n",
    "- 2 pessoas **saudáveis** foram classificadas como **doentes** (falso positivo);\n",
    "\n",
    "- 2 pessoas **doentes** foram classificadas como **saudáveis** (falso negativo).\n",
    "\n",
    "Observe que, nesse contexto, o erro de classificação pode trazer prejuízos para a saúde de um paciente. Um falso negativo significa que o modelo considerou uma pessoa doente como saudável, consequentemente o tratamento adequado pode não ser aplicado ao paciente. Analogamente um falso positivo significa que uma pessoa saudável foi considerada doente, nesse caso um tratamento desnecessário pode ser aplicado. Vale ressaltar que todos os testes diagnósticos estão sujeitos a erros e existem meios para confirmar o resultado, contudo, o ideal é que os erros de classificação sejam minimizados o quanto for possível (otimização de performance).\n",
    "\n",
    "Podemos utilizar o Python para gerar uma matriz de confusão, o código abaixo exemplifica como programar a matriz do problema que estamos discutindo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675fcc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2],\n",
       "       [2, 3]], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "real_values =  [1, 0, 1, 1, 0, 0, 0, 1, 0, 1] # 1-> saudável 0-> doente\n",
    "pred_values = [1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# output:\n",
    "# array([[3, 2],\n",
    "#           [2, 3]])\n",
    "confusion_matrix(real_values , pred_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11406f",
   "metadata": {},
   "source": [
    "A matriz de confusão também pode ser visualizada com uma tabela de cores. Para classificadores multiclasse, termo usado para casos em que há mais de duas classes no conjunto de dados (dataset), essa visualização se torna bastante útil. Abaixo um exemplo de como programar a tabela de cores no Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568129dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "\n",
    "real_values =  [1, 0, 1, 1, 0, 0, 0, 1, 0, 1] # 1-> saudável 0-> doente\n",
    "pred_values = [1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "logreg.classes_ = np.array([-1, 1])\n",
    "\n",
    "cm = confusion_matrix(real_values, pred_values)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\n",
    "\n",
    "disp.plot(values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca892c2",
   "metadata": {},
   "source": [
    "Após contar todos os positivos e negativos, verdadeiros ou falsos, e obter a matriz de confusão podemos calcular as métricas de classificação para avaliar o modelo. Nesse momento focaremos nas principais métricas: acurácia, precision (precisão), recall (sensibilidade ou  revocação), Curva ROC (Receiver Operating Characteristic – Característica de Operação do Receptor) e AUC (Area Under the Curve –  Área sob a curva). \n",
    "\n",
    "É importante destacar que não existem valores de acurácia, ou qualquer outra métrica, que sejam pré-estabelecidos como “adequados”. Os valores adequados para cada métrica devem ser avaliados no contexto de negócio em que o modelo será utilizado. \n",
    "\n",
    "## Acurácia\n",
    "---\n",
    "\n",
    "A acurácia (acc) verifica a taxa de acertos do modelo de classificação, ela é calculada pela razão entre o total de acertos e o total de amostras.\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/1c/8e/57bDP1yc_o.png\" width=\"300\">\n",
    "\n",
    "\n",
    "Essa métrica representa a proporção de verdadeiros positivos e verdadeiros negativos identificados pelo modelo, sendo um bom indicador da performance geral do modelo. Observe que na acurácia não fazemos distinção entre a taxa de acertos e erros das diferentes classes que existem no dataset.\n",
    "\n",
    "O código abaixo ilustra como calculamos a acurácia para o modelo de classificação de pessoas doentes e saudáveis usando o Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28043c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "real_values =  [1, 0, 1, 1, 0, 0, 0, 1, 0, 1] # 1-> saudável 0-> doente\n",
    "pred_values = [1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "accuracy_score(real_values , pred_values) # Output: 0.60 (60% de acurácia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4710b6",
   "metadata": {},
   "source": [
    "## Precision e Recall\n",
    "---\n",
    "\n",
    "\n",
    "As métricas precision e recall avaliam a taxa de erros e acertos de cada uma das classes do modelo. Estas métricas são calculadas a partir da matriz de confusão.\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/ed/c2/F8oUB30a_o.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Usualmente a precisão (precision) é adequada para situações em que os falsos positivos são mais prejudiciais que falsos negativos. Por exemplo, partindo do contexto do teste de gripe, a precisão é apropriada caso seja mais importante ter certeza que os paciente com resultado positivo realmente estão doentes, do que garantir que nenhuma pessoa doente seja classificada como saudável.\n",
    "\n",
    "Analogamente, a sensibilidade (recall) é adequada para casos em que falsos negativos são mais prejudiciais que falsos positivos, isto é, é mais importante garantir que todos os pacientes doentes foram identificados do que evitar que pacientes saudáveis sejam considerados doentes.\n",
    "\n",
    "Em resumo podemos ler essas duas métricas como:\n",
    "\n",
    "- Precision: dentre todas as pessoas classificadas como doentes, quantas estavam realmente doentes?\n",
    "\n",
    "- Recall: dentre todas as pessoas que estavam realmente doentes, quantas foram classificadas corretamente?\n",
    "\n",
    "O código abaixo ilustra como calculamos a precisão e sensibilidade para o modelo de classificação de pessoas doentes e saudáveis usando o Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f64f21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "real_values =  [1, 0, 1, 1, 0, 0, 0, 1, 0, 1] # 1-> saudável 0-> doente\n",
    "pred_values = [1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "precision_score(real_values , pred_values) # output: 0.6\n",
    "recall_score(real_values , pred_values) # output: 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7462efc4",
   "metadata": {},
   "source": [
    "Os resultados obtidos pelo código acima podem ser lidos como:\n",
    "\n",
    "- Precision: dentre todas as pessoas classificadas como doentes, 60% estavam realmente doentes;\n",
    "\n",
    "- Recall: dentre todas as pessoas que estavam realmente doentes, 60% foram identificadas corretamente.\n",
    "\n",
    "Para compreender melhor esses conceitos veja o seguinte vídeo (possui legendas em português, basta ativá-las): https://youtu.be/jr_BcU4QlNE \n",
    "\n",
    "## Curva ROC (Receiver Operating Characteristic) e AUC (Area Under the Curve)\n",
    "---\n",
    "\n",
    "A regressão logística, assim como alguns outros métodos de classificação, nos permite alterar o threshold (limiar do modelo). O valor padrão do threshold é 0.5, o que significa que todas as amostras com mais de 50% de probabilidade são de uma determinada classe e as demais amostras, abaixo de 50%, são da outra classe. No entanto, este valor pode ser modificado com o objetivo de melhorar a performance do modelo. O ajuste deste valor se torna ainda mais importante ao se trabalhar com datasets desbalanceados (muito mais amostras de uma determinada classe do que outra).\n",
    "\n",
    "É possível avaliar a classificação obtida pelo modelo variando o threshold entre 0 e 1. Para cada valor de threshold você irá obter uma matriz de confusão diferente. Uma forma de avaliar a performance de um determinado modelo de classificação é calcular duas métricas da matriz de confusão (recall e especificidade) e expressá-las em um gráfico.\n",
    "\n",
    "A sensibilidade foi explicada anteriormente. A especificidade é uma métrica que avalia a capacidade do modelo de detectar resultados negativos.\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/97/39/jmAp9Uco_o.png\" width=\"500\">\n",
    "\n",
    "O gráfico de sensibilidade versus especificidade é conhecido como Curva ROC (ou curva característica de operação de receptor). Nesse gráfico o eixo Y representa a sensibilidade, ou seja, quanto maior a sensibilidade do teste mais próximo de 1 ele estará (ponto alto), quanto menor a sensibilidade mais próximo de 0 (ponto baixo). \n",
    "\n",
    "Analogamente, o eixo X representa 1-especificidade. Assim, quanto mais perto de 0 maior a especificidade (ponto no começo do eixo), quanto mais perto de 1 menor a especificidade (ponto no final do eixo). Em virtude disso dizemos que quanto mais próximo de 1 a sensitividade melhor.  Para a especificidade, quanto mais próximo de 0 melhor. Logo, concluímos que quanto mais para cima e esquerda o ponto estiver, melhor é o teste.\n",
    "\n",
    "A partir da curva ROC podemos calcular a AUC (Area Under the Curve) uma variável estatística que representa a área abaixo da curva. A AUC é útil para determinar quais curvas tem melhor performance, para entender como isso funciona observe a figura abaixo. \n",
    "\n",
    "<img src = \"https://images2.imgbox.com/54/8d/k8lUBLlO_o.png\" width=\"800\">\n",
    "\n",
    "Devido às características da curva ROC, modelos de baixa performance terão curvas mais “baixas” (próximas da linha pontilhada) e com menor área abaixo da curva (AUC mais próximo de 0). Analogamente modelos com melhor performance terão a curva mais “alta” (próxima do canto superior esquerdo, como a curva laranja) e maior área abaixo da curva (AUC mais próximo de 1). \n",
    "\n",
    "A curva ROC nos ajuda a determinar o melhor threshold para um determinado problema. Em outras palavras, podemos escolher o modelo que tem a menor taxa de falso positivo e que, simultaneamente, apresenta a melhor sensitividade.\n",
    "\n",
    "O código abaixo ilustra como esboçamos a **curva ROC** usando o Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "plot_roc_curve(logreg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fc1b3",
   "metadata": {},
   "source": [
    "Os gráficos abaixo foram gerados com duas abordagens de modelagem distintas, Árvores de Decisão e Regressão Logística. O desempenho dos dois modelos é bem diferente. A abordagem utilizando Árvores de Decisão apresenta uma AUC de 0.98, uma performance superior à do modelo de Regressão Logística. Esse é um exemplo de como podemos usar essas métricas para avaliar um modelo.\n",
    "\n",
    "<img src = \"https://images2.imgbox.com/f0/ea/HcRJ7CoS_o.png\" width=\"700\">\n",
    "\n",
    "\n",
    "## Por fim…\n",
    "\n",
    "Utilizando o problema de classificação de pacientes doentes e saudáveis refletimos sobre a relação entre contexto de negócio e as métricas do modelo. A classificação errada de um paciente doente como saudável pode ser extremamente danosa, uma vez que ele pode perder um tempo valioso para o tratamento da doença. Ao passo que um paciente saudável e classificado como doente pode ser submetido a outros exames, aumentando os custos do diagnóstico.\n",
    "\n",
    "As métricas de classificação nos permitem fazer uma avaliação objetiva sobre o desenvolvimento e performance do modelo, podendo ser utilizadas também para a implementação da solução. Vale ressaltar que não se deve pensar em uma métrica como melhor ou pior que a outra, mas sim, analisar o problema dentro de seu contexto e escolher a (ou as) que melhor se adapta(m). Aproveite para refletir sobre problemas de classificação similares e faça esta análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a846836",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
